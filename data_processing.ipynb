{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from symspellpy.helpers import to_similarity\n",
    "\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in input data directly from the homework assignment excel file. Name changed to 'input.xlsx'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('input.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paypal * US - Doordash</td>\n",
       "      <td>{\"brands\":[{\"1\":\"paypal\", \"2\":\"doordash\"}], \"s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>payal * US NY - Doodash</td>\n",
       "      <td>{\"brands\":[{\"1\":\"paypal\", \"2\":\"doordash\"}], \"s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sq* NJ SEAMLSS 2017777777</td>\n",
       "      <td>{\"brands\":[{\"1\":\"sq\", \"2\":\"seamless\"}], \"state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEAMLSS MCd</td>\n",
       "      <td>{\"brands\":[{\"1\":\"seamless\", \"2\":\"mcdonalds\"}],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>McDOnalds UBEREATS</td>\n",
       "      <td>{\"brands\":[{\"1\":\"mcdonalds\", \"2\":\"ubereats\"}],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Input  \\\n",
       "0     paypal * US - Doordash   \n",
       "1    payal * US NY - Doodash   \n",
       "2  sq* NJ SEAMLSS 2017777777   \n",
       "3                SEAMLSS MCd   \n",
       "4         McDOnalds UBEREATS   \n",
       "\n",
       "                                              Output  \n",
       "0  {\"brands\":[{\"1\":\"paypal\", \"2\":\"doordash\"}], \"s...  \n",
       "1  {\"brands\":[{\"1\":\"paypal\", \"2\":\"doordash\"}], \"s...  \n",
       "2  {\"brands\":[{\"1\":\"sq\", \"2\":\"seamless\"}], \"state...  \n",
       "3  {\"brands\":[{\"1\":\"seamless\", \"2\":\"mcdonalds\"}],...  \n",
       "4  {\"brands\":[{\"1\":\"mcdonalds\", \"2\":\"ubereats\"}],...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection of the given inputs shows state and country names are not misspelled. A simple search yields text files of states abbreviations and 2-letter ISO country codes to match tokens against. \n",
    "\n",
    "Importing list of states and country codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load list of states\n",
    "with open('states.txt') as f:\n",
    "    states = f.readlines()\n",
    "    \n",
    "states = [x.rstrip().lower() for x in states] \n",
    "#load list of 2-letter country codes\n",
    "with open('ISO_country_codes.txt') as f:\n",
    "    countries = f.readlines()\n",
    "\n",
    "countries = [x.rstrip().split(';')[1].lower() for x in countries] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ak', 'al', 'az', 'ar', 'ca', 'co', 'ct', 'de', 'dc', 'fl', 'ga', 'hi', 'id', 'il', 'in', 'ia', 'ks', 'ky', 'la', 'me', 'mt', 'ne', 'nv', 'nh', 'nj', 'nm', 'ny', 'nc', 'nd', 'oh', 'ok', 'or', 'md', 'ma', 'mi', 'mn', 'ms', 'mo', 'pa', 'ri', 'sc', 'sd', 'tn', 'tx', 'ut', 'vt', 'va', 'wa', 'wv', 'wi', 'wy']\n"
     ]
    }
   ],
   "source": [
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['af', 'ax', 'al', 'dz', 'as', 'ad', 'ao', 'ai', 'aq', 'ag', 'ar', 'am', 'aw', 'au', 'at', 'az', 'bs', 'bh', 'bd', 'bb', 'by', 'be', 'bz', 'bj', 'bm', 'bt', 'bo', 'bq', 'ba', 'bw', 'bv', 'br', 'io', 'bn', 'bg', 'bf', 'bi', 'kh', 'cm', 'ca', 'cv', 'ky', 'cf', 'td', 'cl', 'cn', 'cx', 'cc', 'co', 'km', 'cg', 'cd', 'ck', 'cr', 'ci', 'hr', 'cu', 'cw', 'cy', 'cz', 'dk', 'dj', 'dm', 'do', 'ec', 'eg', 'sv', 'gq', 'er', 'ee', 'et', 'fk', 'fo', 'fj', 'fi', 'fr', 'gf', 'pf', 'tf', 'ga', 'gm', 'ge', 'de', 'gh', 'gi', 'gr', 'gl', 'gd', 'gp', 'gu', 'gt', 'gg', 'gn', 'gw', 'gy', 'ht', 'hm', 'va', 'hn', 'hk', 'hu', 'is', 'in', 'id', 'ir', 'iq', 'ie', 'im', 'il', 'it', 'jm', 'jp', 'je', 'jo', 'kz', 'ke', 'ki', 'kp', 'kr', 'kw', 'kg', 'la', 'lv', 'lb', 'ls', 'lr', 'ly', 'li', 'lt', 'lu', 'mo', 'mk', 'mg', 'mw', 'my', 'mv', 'ml', 'mt', 'mh', 'mq', 'mr', 'mu', 'yt', 'mx', 'fm', 'md', 'mc', 'mn', 'me', 'ms', 'ma', 'mz', 'mm', 'na', 'nr', 'np', 'nl', 'nc', 'nz', 'ni', 'ne', 'ng', 'nu', 'nf', 'mp', 'no', 'om', 'pk', 'pw', 'ps', 'pa', 'pg', 'py', 'pe', 'ph', 'pn', 'pl', 'pt', 'pr', 'qa', 're', 'ro', 'ru', 'rw', 'bl', 'sh', 'kn', 'lc', 'mf', 'pm', 'vc', 'ws', 'sm', 'st', 'sa', 'sn', 'rs', 'sc', 'sl', 'sg', 'sx', 'sk', 'si', 'sb', 'so', 'za', 'gs', 'ss', 'es', 'lk', 'sd', 'sr', 'sj', 'sz', 'se', 'ch', 'sy', 'tw', 'tj', 'tz', 'th', 'tl', 'tg', 'tk', 'to', 'tt', 'tn', 'tr', 'tm', 'tc', 'tv', 'ug', 'ua', 'ae', 'gb', 'us', 'um', 'uy', 'uz', 'vu', 've', 'vn', 'vg', 'vi', 'wf', 'eh', 'ye', 'zm', 'zw']\n"
     ]
    }
   ],
   "source": [
    "print(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract brands, state, country, and phone number from input string\n",
    "\n",
    "Data processing approach:\n",
    "\n",
    "To yield expected output, each row is stripped of non-alphanumeric numbers, except for '.', which forms part of brand names. Input is then space-separated into tokens, which are identified as either phone numbers, states, countries, or brands. \n",
    "- Phone numbers must be all-numeric tokens of length 10.\n",
    "- States are identified if belonging to state list.\n",
    "- Country codes are identified if belongign ot country code list.\n",
    "- Brand names are any tokens that do not fall into the above categories.\n",
    "\n",
    "The out list maintains each processed row as a list of dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out= []\n",
    "\n",
    "for row in data.Input:\n",
    "    #lowercase and elminate special characters and punction except for '.' and spaces\n",
    "    row = ''.join(c for c in row if c.isalnum() or c in ['.', ' '])\n",
    "    \n",
    "    #list of of space-separated tokens\n",
    "    l = row.lower().strip().split()\n",
    "    \n",
    "    #output row\n",
    "    d = {\"brands\":[{}], \"state\":\"\", \"country\": \"\", \"ph no\":\"\"}\n",
    "    brand_count = 1\n",
    "    for token in l:\n",
    "        \n",
    "        #check if token is phone number, state, or country-- otherwise = brand\n",
    "        if len(token)==10 and token.isnumeric():\n",
    "            d['ph no'] = token\n",
    "        elif token in states:\n",
    "            d['state'] = token\n",
    "        elif token in countries:\n",
    "            d['country'] = token\n",
    "        else:\n",
    "            d['brands'][0][str(brand_count)] = token\n",
    "            brand_count+=1\n",
    "    \n",
    "    out.append(d)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is in correct format. Next, brand names must be corrected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'brands': [{'1': 'paypal', '2': 'doordash'}],\n",
      "  'country': 'us',\n",
      "  'ph no': '',\n",
      "  'state': ''},\n",
      " {'brands': [{'1': 'payal', '2': 'doodash'}],\n",
      "  'country': 'us',\n",
      "  'ph no': '',\n",
      "  'state': 'ny'},\n",
      " {'brands': [{'1': 'sq', '2': 'seamlss'}],\n",
      "  'country': '',\n",
      "  'ph no': '2017777777',\n",
      "  'state': 'nj'},\n",
      " {'brands': [{'1': 'seamlss', '2': 'mcd'}],\n",
      "  'country': '',\n",
      "  'ph no': '',\n",
      "  'state': ''},\n",
      " {'brands': [{'1': 'mcdonalds', '2': 'ubereats'}],\n",
      "  'country': '',\n",
      "  'ph no': '',\n",
      "  'state': ''},\n",
      " {'brands': [{'1': 'giftcard'}], 'country': 'us', 'ph no': '', 'state': 'ca'},\n",
      " {'brands': [{'1': 'hotels.com', '2': 'expedia', '3': 'sheraton'}],\n",
      "  'country': '',\n",
      "  'ph no': '',\n",
      "  'state': ''},\n",
      " {'brands': [{'1': 'chipotl', '2': 'postmates'}],\n",
      "  'country': '',\n",
      "  'ph no': '',\n",
      "  'state': ''},\n",
      " {'brands': [{'1': 'paypal', '2': 'grubhub'}],\n",
      "  'country': 'us',\n",
      "  'ph no': '',\n",
      "  'state': ''},\n",
      " {'brands': [{'1': 'payal', '2': 'ubereats'}],\n",
      "  'country': 'us',\n",
      "  'ph no': '',\n",
      "  'state': 'ny'},\n",
      " {'brands': [{'1': 'sq', '2': 'doordash'}],\n",
      "  'country': '',\n",
      "  'ph no': '5745745745',\n",
      "  'state': 'nj'},\n",
      " {'brands': [{'1': 'seamlss', '2': 'subway'}],\n",
      "  'country': '',\n",
      "  'ph no': '',\n",
      "  'state': ''},\n",
      " {'brands': [{'1': 'wendys', '2': 'ubereats'}],\n",
      "  'country': '',\n",
      "  'ph no': '',\n",
      "  'state': ''},\n",
      " {'brands': [{'1': 'giftcard'}], 'country': 'us', 'ph no': '', 'state': 'tx'},\n",
      " {'brands': [{'1': 'booking.com', '2': 'priceline', '3': 'marriott'}],\n",
      "  'country': '',\n",
      "  'ph no': '',\n",
      "  'state': ''},\n",
      " {'brands': [{'1': 'chickfila', '2': 'postmates'}],\n",
      "  'country': '',\n",
      "  'ph no': '',\n",
      "  'state': ''}]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling correction and fuzzy string search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load spell check library and brand dictionary. \n",
    "\n",
    "SymSpell performs spell-checking by loading a dictionary of terms and their respective frequencies for weight in predictions. When an out-of-dictionary term is encountered, it computes candidate terms from its dictionary based on how many edits are required to get from input word to in-dictionary terms, as well as in-dictionary term frequencies as likelihood of term. It uses the Symmetic Delete spelling correction algorithm and excels in speed. For more information about this algorithm and how it compares to others, see <a href=\"https://towardsdatascience.com/symspell-vs-bk-tree-100x-faster-fuzzy-string-search-spell-checking-c4f10d80a078\">this post</a>.\n",
    "\n",
    "Maximal edit distance chosen to be 6 here because it takes 6 edits to get from input token \"mcd\" to desired token \"mcdonalds\", the largest edit distance necessary for our inputs. Note, the more edits are necessary, the more computationally expensive it will be to spell-check words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_spell = SymSpell(max_dictionary_edit_distance=6, prefix_length=7)\n",
    "sym_spell.load_dictionary('brands_sep.txt', 0, 1, separator=\";\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show this a robust solution, the brand dictionary includes names of other popular tech brands to potentially correct misspellings to. All brand names are weighted equally.\n",
    "\n",
    "Here is a preview of the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('paypal', 2), ('doordash', 2), ('sq', 1), ('seamless', 1), ('mcdonalds', 1), ('ubereats', 1), ('hotels.com', 1), ('expedia', 1), ('sheraton', 1), ('chipotle', 1), ('postmates', 2), ('grubhub', 1), ('subway', 1), ('wendys', 1), ('giftcard', 1), ('booking.com', 2), ('priceline', 1), ('marriott', 1), ('chickfila', 1), ('Amazon', 1), ('Google', 1), ('Apple', 1), ('Microsoft', 1), ('Facebook', 1), ('Samsung', 1), ('Huawei', 1), ('WeChat', 1), ('YouTube', 1), ('Taobao', 1), ('IBM', 1), ('Tmall', 1), ('Intel', 1), ('Instagram', 1), ('accenture', 1), ('Oracle', 1), ('Cisco', 1), ('Netflix', 1), ('Alibaba.com', 1), ('SAP', 1), ('Uber', 1), ('NetEase', 1), ('JD.com', 1), ('Sony', 1), ('Midea', 1), ('Panasonic', 1), ('Airbnb', 1), ('Salesforce', 1), ('Nokia', 1), ('Gree', 1), ('Canon', 1), ('Adobe', 1), ('HP', 1), ('Baidu', 1), ('3M', 1), ('TSMC', 1), ('Cognizant', 1), ('Yahoo! Group', 1), ('eBay', 1), ('LinkedIn', 1), ('Haier', 1), ('Playstation', 1), ('Qualcomm', 1), ('Broadcom', 1), ('Infosys', 1), ('Philips', 1), ('Hikvision', 1), ('Capgemini', 1), ('Youku', 1), ('Xiaomi', 1), ('HPE', 1), ('ctrip.com', 1), ('FIS', 1), ('Xbox', 1), ('Nintendo', 1), ('Lenovo', 1), ('VMWARE', 1), ('Rakuten', 1), ('HCL', 1), ('Nvidia', 1), ('ZTE', 1), ('Fiserv', 1), ('Wipro', 1), ('Spotify', 1), ('Twitter', 1), ('Atos', 1), ('Cerner', 1), ('Sharp', 1), ('Expedia.com', 1), ('BOE', 1), ('Naver', 1), ('CGI', 1), ('QVC', 1), ('Servicenow', 1), ('Amadeus', 1), ('ASML', 1), ('Kyocera', 1), ('Nidec', 1), ('Ericsson', 1)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_spell.words.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of correcting the token \"mcd\" to \"mcdonalds\".\n",
    "\n",
    "Choosing the corrected word simply from the one requiring the fewest edits can lead to errors given short tokens, such as \"mcd\", which could be entirely changed to a different in-dictionary token with fewer edits than the real target, \"mcdonalds\". \n",
    "\n",
    "Similarity measure is calculated using edit distance as (1 - (length / distance))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Term: sq, Edit Distance: 3, Similarity : -0.5\n",
      "Candidate Term: IBM, Edit Distance: 3, Similarity : 0.0\n",
      "Candidate Term: SAP, Edit Distance: 3, Similarity : 0.0\n",
      "Candidate Term: HP, Edit Distance: 3, Similarity : -0.5\n",
      "Candidate Term: 3M, Edit Distance: 3, Similarity : -0.5\n",
      "Candidate Term: HPE, Edit Distance: 3, Similarity : 0.0\n",
      "Candidate Term: FIS, Edit Distance: 3, Similarity : 0.0\n",
      "Candidate Term: HCL, Edit Distance: 3, Similarity : 0.0\n",
      "Candidate Term: ZTE, Edit Distance: 3, Similarity : 0.0\n",
      "Candidate Term: BOE, Edit Distance: 3, Similarity : 0.0\n",
      "Candidate Term: CGI, Edit Distance: 3, Similarity : 0.0\n",
      "Candidate Term: QVC, Edit Distance: 3, Similarity : 0.0\n",
      "Candidate Term: Midea, Edit Distance: 4, Similarity : 0.19999999999999996\n",
      "Candidate Term: Baidu, Edit Distance: 4, Similarity : 0.19999999999999996\n",
      "Candidate Term: Nidec, Edit Distance: 4, Similarity : 0.19999999999999996\n",
      "Candidate Term: Cisco, Edit Distance: 4, Similarity : 0.19999999999999996\n",
      "Candidate Term: Tmall, Edit Distance: 4, Similarity : 0.19999999999999996\n",
      "Candidate Term: Amadeus, Edit Distance: 5, Similarity : 0.2857142857142857\n",
      "Candidate Term: wendys, Edit Distance: 5, Similarity : 0.16666666666666663\n",
      "Candidate Term: mcdonalds, Edit Distance: 6, Similarity : 0.33333333333333337\n"
     ]
    }
   ],
   "source": [
    "suggestions = sym_spell.lookup('mcd', Verbosity,\n",
    "                               max_edit_distance=6)\n",
    "\n",
    "for sugg in suggestions:\n",
    "    print('Candidate Term: {}, Edit Distance: {}, Similarity : {}'.format(sugg.term, sugg.distance, to_similarity(sugg.distance, len(sugg.term))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corecting brand names and final output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks each entry and each brand. If a brand is not in dictionary, it looks for candidate terms. \n",
    "\n",
    "We order the suggestions by similarity to original token and then fewest edits should there be a tie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in out:\n",
    "    for key,brand in entry['brands'][0].items():\n",
    "        #if brand not in dictionary, spellcheck\n",
    "        correct = sym_spell.lookup(brand, Verbosity.CLOSEST,\n",
    "                               max_edit_distance=0)\n",
    "        \n",
    "        if not correct:\n",
    "            suggestions = sym_spell.lookup(brand, Verbosity,\n",
    "                               max_edit_distance=6)\n",
    "            \n",
    "            #if only one suggestion, choose it\n",
    "            if len(suggestions)==1:\n",
    "                entry['brands'][0][key] = suggestions[0].term\n",
    "            \n",
    "            #if more than one suggestion, order by similarity to original word, then no. edits\n",
    "            else:\n",
    "                corrections = []\n",
    "                \n",
    "                for sugg in suggestions:\n",
    "                    corrections.append((sugg.term, sugg.distance, to_similarity(sugg.distance, len(sugg.term))))\n",
    "                \n",
    "                #already sorted by minimum edits, sort by similarity (descending)\n",
    "                corrections = sorted(corrections, key=lambda x: -x[2])\n",
    "                entry['brands'][0][key] = corrections[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Output\n",
    "\n",
    "Produced output = desired output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brands': [{'1': 'paypal', '2': 'doordash'}], 'state': '', 'country': 'us', 'ph no': ''}\n",
      "{'brands': [{'1': 'paypal', '2': 'doordash'}], 'state': 'ny', 'country': 'us', 'ph no': ''}\n",
      "{'brands': [{'1': 'sq', '2': 'seamless'}], 'state': 'nj', 'country': '', 'ph no': '2017777777'}\n",
      "{'brands': [{'1': 'seamless', '2': 'mcdonalds'}], 'state': '', 'country': '', 'ph no': ''}\n",
      "{'brands': [{'1': 'mcdonalds', '2': 'ubereats'}], 'state': '', 'country': '', 'ph no': ''}\n",
      "{'brands': [{'1': 'giftcard'}], 'state': 'ca', 'country': 'us', 'ph no': ''}\n",
      "{'brands': [{'1': 'hotels.com', '2': 'expedia', '3': 'sheraton'}], 'state': '', 'country': '', 'ph no': ''}\n",
      "{'brands': [{'1': 'chipotle', '2': 'postmates'}], 'state': '', 'country': '', 'ph no': ''}\n",
      "{'brands': [{'1': 'paypal', '2': 'grubhub'}], 'state': '', 'country': 'us', 'ph no': ''}\n",
      "{'brands': [{'1': 'paypal', '2': 'ubereats'}], 'state': 'ny', 'country': 'us', 'ph no': ''}\n",
      "{'brands': [{'1': 'sq', '2': 'doordash'}], 'state': 'nj', 'country': '', 'ph no': '5745745745'}\n",
      "{'brands': [{'1': 'seamless', '2': 'subway'}], 'state': '', 'country': '', 'ph no': ''}\n",
      "{'brands': [{'1': 'wendys', '2': 'ubereats'}], 'state': '', 'country': '', 'ph no': ''}\n",
      "{'brands': [{'1': 'giftcard'}], 'state': 'tx', 'country': 'us', 'ph no': ''}\n",
      "{'brands': [{'1': 'booking.com', '2': 'priceline', '3': 'marriott'}], 'state': '', 'country': '', 'ph no': ''}\n",
      "{'brands': [{'1': 'chickfila', '2': 'postmates'}], 'state': '', 'country': '', 'ph no': ''}\n"
     ]
    }
   ],
   "source": [
    "for row in out:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"brands\":[{\"1\":\"paypal\", \"2\":\"doordash\"}], \"state\":\"\", \"country\":\"us\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"paypal\", \"2\":\"doordash\"}], \"state\":\"ny\", \"country\":\"us\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"sq\", \"2\":\"seamless\"}], \"state\":\"nj\", \"country\":\"\",\"ph no\":\"2017777777\"}\n",
      "{\"brands\":[{\"1\":\"seamless\", \"2\":\"mcdonalds\"}], \"state\":\"\", \"country\":\"\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"mcdonalds\", \"2\":\"ubereats\"}], \"state\":\"\", \"country\":\"\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"giftcard\"}], \"state\":\"ca\", \"country\":\"us\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"hotels.com\", \"2\":\"expedia\", \"3\":\"sheraton\"}], \"state\":\"\", \"country\":\"\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"chipotle\", \"2\":\"postmates\"}], \"state\":\"\", \"country\":\"\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"paypal\", \"2\":\"grubhub\"}], \"state\":\"\", \"country\":\"us\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"paypal\", \"2\":\"ubereats\"}], \"state\":\"ny\", \"country\":\"us\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"sq\", \"2\":\"doordash\"}], \"state\":\"nj\", \"country\":\"\",\"ph no\":\"5745745745\"}\n",
      "{\"brands\":[{\"1\":\"seamless\", \"2\":\"subway\"}], \"state\":\"\", \"country\":\"\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"wendys\", \"2\":\"ubereats\"}], \"state\":\"\", \"country\":\"\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"giftcard\"}], \"state\":\"tx\", \"country\":\"us\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"booking.com\", \"2\":\"priceline\", \"3\":\"marriott\"}], \"state\":\"\", \"country\":\"\",\"ph no\":\"\"}\n",
      "{\"brands\":[{\"1\":\"chickfila\", \"2\":\"postmates\"}], \"state\":\"\", \"country\":\"\",\"ph no\":\"\"}\n"
     ]
    }
   ],
   "source": [
    "for row in data.Output:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
